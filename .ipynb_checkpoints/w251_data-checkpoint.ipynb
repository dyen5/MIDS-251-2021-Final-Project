{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the data science stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# File system access\n",
    "import os\n",
    "from shutil import copy2\n",
    "\n",
    "# Image importing\n",
    "import cv2\n",
    "\n",
    "# Tracking progress\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path\n",
    "parent_dir = '/home/ubuntu/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data - keep Kaggle order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCP_96_1328_0032.png</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>94</td>\n",
       "      <td>512</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCP_96_1328_0035.png</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>106</td>\n",
       "      <td>512</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCP_96_1328_0036.png</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>105</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCP_96_1328_0037.png</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>104</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCP_96_1328_0038.png</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>103</td>\n",
       "      <td>512</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id  class  xmin  ymin  xmax  ymax\n",
       "0  NCP_96_1328_0032.png      2     9    94   512   405\n",
       "1  NCP_96_1328_0035.png      2    10   106   512   405\n",
       "2  NCP_96_1328_0036.png      2    10   105   512   406\n",
       "3  NCP_96_1328_0037.png      2    11   104   512   406\n",
       "4  NCP_96_1328_0038.png      2    11   103   512   406"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in train, validation, and test\n",
    "train_labels = pd.read_csv(parent_dir + 'train_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "val_labels = pd.read_csv(parent_dir + 'val_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "test_labels = pd.read_csv(parent_dir + 'test_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "print(len(train_labels))\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/ubuntu/data/2A_images_reorg2/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d0c53945d75f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# create main folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'2A_images_reorg2/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# create subfolders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/ubuntu/data/2A_images_reorg2/'"
     ]
    }
   ],
   "source": [
    "# create folders\n",
    "datasets = ['mini', 'train', 'hyper', 'val', 'test']\n",
    "labels = ['Normal', 'Pneumonia', 'Covid']\n",
    "\n",
    "# create main folder\n",
    "output_dir = parent_dir+'2A_images_reorg2/'\n",
    "os.mkdir(output_dir)\n",
    "\n",
    "# create subfolders\n",
    "for d in datasets:\n",
    "    os.mkdir(output_dir+d)\n",
    "    for l in labels:\n",
    "        os.mkdir(output_dir+d+'/'+l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move images to folders\n",
    "def move_files(img_folder, img_names, labels, output_dir):\n",
    "    for i, img in enumerate(tqdm(img_names, position=0, leave=True)):\n",
    "        if labels[i] == 0:\n",
    "            copy2(img_folder+'/'+img, output_dir+'Normal')\n",
    "        elif labels[i] == 1:\n",
    "            copy2(img_folder+'/'+img, output_dir+'Pneumonia')\n",
    "        elif labels[i] == 2:\n",
    "            copy2(img_folder+'/'+img, output_dir+'Covid')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25658/25658 [00:09<00:00, 2846.33it/s]\n"
     ]
    }
   ],
   "source": [
    "img_folder=\"/home/ubuntu/data/2A_images/\"\n",
    "\n",
    "# train\n",
    "move_files(img_folder, train_labels['image_id'], train_labels['class'], output_dir+'train/')\n",
    "\n",
    "# hyper\n",
    "move_files(img_folder, train_labels['image_id'][136445:], train_labels['class'][136445:], output_dir+'hyper/')\n",
    "\n",
    "# val\n",
    "move_files(img_folder, val_labels['image id'], val_labels['class'], output_dir+'val/')\n",
    "\n",
    "# test\n",
    "move_files(img_folder, test_labels['image_id'], test_labels['class'], output_dir+'test/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data - randomize images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCP_96_1328_0032.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCP_96_1328_0035.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCP_96_1328_0036.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCP_96_1328_0037.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCP_96_1328_0038.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id  class\n",
       "0  NCP_96_1328_0032.png      2\n",
       "1  NCP_96_1328_0035.png      2\n",
       "2  NCP_96_1328_0036.png      2\n",
       "3  NCP_96_1328_0037.png      2\n",
       "4  NCP_96_1328_0038.png      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in train, validation, and test\n",
    "train_labels = pd.read_csv(parent_dir + 'train_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "val_labels = pd.read_csv(parent_dir + 'val_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "test_labels = pd.read_csv(parent_dir + 'test_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "all_labels = pd.concat([train_labels, val_labels, test_labels])\n",
    "all_labels = all_labels[['image_id', 'class']]\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in images - takes about 17 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images\n",
    "def load_images_from_folder(folder, dim):\n",
    "    '''\n",
    "    folder = file path to image folder\n",
    "    dim = tuple (width, height), output array of images\n",
    "    '''\n",
    "    img_name = []\n",
    "    img_array = []\n",
    "    \n",
    "    # use tqdm to track progress\n",
    "    # opens each image iteratively from folder\n",
    "    for filename in tqdm(os.listdir(folder), position=0, leave=True):\n",
    "        \n",
    "        # save image name\n",
    "        img_name.append(filename)\n",
    "        \n",
    "        # reads image \n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        \n",
    "        if img is not None:\n",
    "            # convert to gray scale\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # resize image\n",
    "            resized = cv2.resize(gray, dim, interpolation = cv2.INTER_AREA)\n",
    "            #resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA\n",
    "\n",
    "            # append image\n",
    "            img_array.append(resized)\n",
    "    \n",
    "    return img_name, img_array\n",
    "img_folder=\"/home/ubuntu/data/2A_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194922/194922 [15:05<00:00, 215.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "dim = (256,256)\n",
    "img_name, img_array = load_images_from_folder(img_folder, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194922, 256, 256)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "img_name = np.array(img_name)\n",
    "img_array = np.array(img_array)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194922/194922 [28:20<00:00, 114.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sort labels by image name order - 27 minutes\n",
    "sorted_labels = []\n",
    "for i in tqdm(img_name, position=0, leave=True):\n",
    "    a = all_labels['class'][all_labels['image_id'] == i]\n",
    "    sorted_labels.append(int(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "sorted_labels = np.array(sorted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random indices\n",
    "all_idx = np.random.choice(img_array.shape[0], img_array.shape[0], replace=False)\n",
    "\n",
    "# Randomize data\n",
    "img_name = img_name[all_idx]\n",
    "img_array = img_array[all_idx]\n",
    "sorted_labels = sorted_labels[all_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset to train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set to debug\n",
    "mini_img = img_name[0:10000]\n",
    "mini_X = img_array[0:10000]\n",
    "mini_y = sorted_labels[0:10000]\n",
    "\n",
    "# 70% train\n",
    "train_img = img_name[0:136445]\n",
    "train_X = img_array[0:136445]\n",
    "train_y = sorted_labels[0:136445]\n",
    "\n",
    "# 10% hyper parameter tuning\n",
    "hyper_img = img_name[136445:155938]\n",
    "hyper_X = img_array[136445:155938]\n",
    "hyper_y = sorted_labels[136445:155938]\n",
    "\n",
    "# 10% valdiation\n",
    "val_img = img_name[155938:175430]\n",
    "val_X = img_array[155938:175430]\n",
    "val_y = sorted_labels[155938:175430]\n",
    "\n",
    "# 10% test\n",
    "test_img = img_name[175430:]\n",
    "test_X = img_array[175430:]\n",
    "test_y = sorted_labels[175430:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution of classes in mini, train, hyper, and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3065 0.2    0.4935]\n",
      "[0.30869581 0.20586317 0.48544102]\n",
      "[0.30646899 0.20715129 0.48637973]\n",
      "[0.30427868 0.2085984  0.48712292]\n",
      "[0.31079417 0.2102401  0.47896573]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(mini_y, return_counts=True)[1]/(np.unique(mini_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(train_y, return_counts=True)[1]/(np.unique(train_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(hyper_y, return_counts=True)[1]/(np.unique(hyper_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(val_y, return_counts=True)[1]/(np.unique(val_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(test_y, return_counts=True)[1]/(np.unique(test_y, return_counts=True)[1].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganize images into relevenat folders.  These images can be pulled in using Pytorch's ImageFolder later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders\n",
    "datasets = ['mini', 'train', 'hyper', 'val', 'test']\n",
    "labels = ['Normal', 'Pneumonia', 'Covid']\n",
    "\n",
    "# create main folder\n",
    "output_dir = parent_dir+'2A_images_reorg/'\n",
    "os.mkdir(output_dir)\n",
    "\n",
    "# create subfolders\n",
    "for d in datasets:\n",
    "    os.mkdir(output_dir+d)\n",
    "    for l in labels:\n",
    "        os.mkdir(output_dir+d+'/'+l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move images to folders\n",
    "def move_files(img_folder, img_names, labels, output_dir):\n",
    "    for i, img in enumerate(tqdm(img_names, position=0, leave=True)):\n",
    "        if labels[i] == 0:\n",
    "            copy2(img_folder+'/'+img, output_dir+'Normal')\n",
    "        elif labels[i] == 1:\n",
    "            copy2(img_folder+'/'+img, output_dir+'Pneumonia')\n",
    "        elif labels[i] == 2:\n",
    "            copy2(img_folder+'/'+img, output_dir+'Covid')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136445/136445 [03:24<00:00, 666.92it/s]\n",
      "100%|██████████| 19493/19493 [00:40<00:00, 485.70it/s]\n",
      "100%|██████████| 19492/19492 [00:39<00:00, 497.13it/s]\n",
      "100%|██████████| 19492/19492 [00:39<00:00, 496.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# mini\n",
    "#move_files(img_folder, mini_img, mini_y, output_dir+'mini/')\n",
    "\n",
    "# train\n",
    "move_files(img_folder, train_img, train_y, output_dir+'train/')\n",
    "\n",
    "# hyper\n",
    "move_files(img_folder, hyper_img, hyper_y, output_dir+'hyper/')\n",
    "\n",
    "# val\n",
    "move_files(img_folder, val_img, val_y, output_dir+'val/')\n",
    "\n",
    "# test\n",
    "move_files(img_folder, test_img, test_y, output_dir+'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save image names to file\n",
    "os.mkdir(output_dir+'img_name/')\n",
    "np.save(output_dir+'img_name/'+'mini_img_name', mini_img)\n",
    "np.save(output_dir+'img_name/'+'train_img_name', train_img)\n",
    "np.save(output_dir+'img_name/'+'hyper_img_name', hyper_img)\n",
    "np.save(output_dir+'img_name/'+'val_img_name', val_img)\n",
    "np.save(output_dir+'img_name/'+'test_img_name', test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or Save numpy to files, which can be loaded, converted to tenors, and to dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('mini_X', mini_X)\n",
    "np.save('mini_y', mini_y)\n",
    "np.save('train_X', train_X)\n",
    "np.save('train_y', train_y)\n",
    "np.save('hyper_X', hyper_X)\n",
    "np.save('hyper_y', hyper_y)\n",
    "np.save('val_X', val_X)\n",
    "np.save('val_y', val_y)\n",
    "np.save('test_X', test_X)\n",
    "np.save('test_y', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load numpy files - 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini_X = np.load('mini_X.npy')\n",
    "#mini_y = np.load('mini_y.npy')\n",
    "train_X = np.load('train_X.npy')\n",
    "train_y = np.load('train_y.npy')\n",
    "#hyper_X = np.load('hyper_X.npy')\n",
    "#hyper_y = np.load('hyper_y.npy')\n",
    "#val_X = np.load('val_X.npy')\n",
    "#val_y = np.load('val_y.npy')\n",
    "#test_X = np.load('test_X.npy')\n",
    "#test_y = np.load('test_y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136445, 256, 256)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to tensors - one at a time otherwise kernel will die b/c of OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mini\n",
    "mini_seq_CNN = torch.from_numpy(mini_X).float()\n",
    "mini_y_CNN = torch.tensor(mini_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq_CNN = torch.from_numpy(train_X).float()\n",
    "train_y_CNN = torch.tensor(train_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hyperparameter tuning set\n",
    "hyper_seq_CNN = torch.from_numpy(hyper_X).float()\n",
    "hyper_y_CNN = torch.tensor(hyper_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation set\n",
    "val_seq_CNN = torch.from_numpy(val_X).float()\n",
    "val_y_CNN = torch.tensor(val_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test set\n",
    "test_seq_CNN = torch.from_numpy(test_X).float()\n",
    "test_y_CNN = torch.tensor(test_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally save tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mini_seq_CNN, 'mini_seq_CNN.pt')\n",
    "torch.save(mini_y_CNN, 'mini_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_seq_CNN, 'train_seq_CN.pt')\n",
    "torch.save(train_y_CNN, 'train_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hyper_seq_CNN, 'hyper_seq_CNN.pt')\n",
    "torch.save(hyper_y_CNN, 'hyper_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_seq_CNN, 'val_seq_CNN.pt')\n",
    "torch.save(val_y_CNN,'val_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_seq_CNN, 'test_seq_CNN.pt')\n",
    "torch.save(test_y_CNN,'test_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to TensorDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data_CNN = TensorDataset(mini_seq_CNN, mini_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_CNN = TensorDataset(train_seq_CNN, train_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_data_CNN = TensorDataset(hyper_seq_CNN, hyper_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_CNN = TensorDataset(val_seq_CNN, val_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_seq_CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-33cc8823edab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_seq_CNN' is not defined"
     ]
    }
   ],
   "source": [
    "test_data_CNN = TensorDataset(test_seq_CNN, test_y_CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs (images or numpy files) should be in the parent directory for you in model training and test."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
