{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the data science stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# File system access\n",
    "import os\n",
    "\n",
    "# Image importing\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "# Tracking progress\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Random seed\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCP_96_1328_0032.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCP_96_1328_0035.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCP_96_1328_0036.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCP_96_1328_0037.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCP_96_1328_0038.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_id  class\n",
       "0  NCP_96_1328_0032.png      2\n",
       "1  NCP_96_1328_0035.png      2\n",
       "2  NCP_96_1328_0036.png      2\n",
       "3  NCP_96_1328_0037.png      2\n",
       "4  NCP_96_1328_0038.png      2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in train, validation, and test\n",
    "train_labels = pd.read_csv('/home/ubuntu/data/train_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "val_labels = pd.read_csv('/home/ubuntu/data/val_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "test_labels = pd.read_csv('/home/ubuntu/data/test_COVIDx_CT-2A.txt', sep=' ',\n",
    "                         names=['image_id','class','xmin', 'ymin', 'xmax', 'ymax'])\n",
    "\n",
    "all_labels = pd.concat([train_labels, val_labels, test_labels])\n",
    "all_labels = all_labels[['image_id', 'class']]\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in images - takes about 17 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images\n",
    "def load_images_from_folder(folder, dim):\n",
    "    '''\n",
    "    folder = file path to image folder\n",
    "    dim = tuple (width, height), output array of images\n",
    "    '''\n",
    "    img_name = []\n",
    "    img_array = []\n",
    "    \n",
    "    # use tqdm to track progress\n",
    "    # opens each image iteratively from folder\n",
    "    for filename in tqdm(os.listdir(folder), position=0, leave=True):\n",
    "        \n",
    "        # save image name\n",
    "        img_name.append(filename)\n",
    "        \n",
    "        # reads image \n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        \n",
    "        if img is not None:\n",
    "            # convert to gray scale\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # resize image\n",
    "            resized = cv2.resize(gray, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "            # append image\n",
    "            img_array.append(resized)\n",
    "    \n",
    "    return img_name, img_array\n",
    "folder=\"/home/ubuntu/data/2A_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194922/194922 [12:28<00:00, 260.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run function\n",
    "dim = (256,256)\n",
    "img_name, img_array = load_images_from_folder(folder, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194922, 256, 256)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "img_array = np.array(img_array)\n",
    "img_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 194922/194922 [26:58<00:00, 120.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Sort labels by image name order - 27 minutes\n",
    "sorted_labels = []\n",
    "for i in tqdm(img_name, position=0, leave=True):\n",
    "    a = all_labels['class'][all_labels['image_id'] == i]\n",
    "    sorted_labels.append(int(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "sorted_labels = np.array(sorted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random indices\n",
    "all_idx = np.random.choice(img_array.shape[0], img_array.shape[0], replace=False)\n",
    "\n",
    "# Randomize data\n",
    "img_array = img_array[all_idx]\n",
    "sorted_labels = sorted_labels[all_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset to train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set to debug\n",
    "mini_X = img_array[0:10000]\n",
    "mini_y = sorted_labels[0:10000]\n",
    "\n",
    "# 70% train\n",
    "train_X = img_array[0:136445]\n",
    "train_y = sorted_labels[0:136445]\n",
    "\n",
    "# 10% hyper parameter tuning\n",
    "hyper_X = img_array[136445:155938]\n",
    "hyper_y = sorted_labels[136445:155938]\n",
    "\n",
    "# 10% valdiation\n",
    "val_X = img_array[155938:175430]\n",
    "val_y = sorted_labels[155938:175430]\n",
    "\n",
    "# 10% test\n",
    "test_X = img_array[175430:]\n",
    "test_y = sorted_labels[175430:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution of classes in mini, train, hyper, and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3049 0.206  0.4891]\n",
      "[0.30685624 0.20610502 0.48703873]\n",
      "[0.31149643 0.21161443 0.47688914]\n",
      "[0.31346193 0.20608455 0.48045352]\n",
      "[0.30946029 0.20659758 0.48394213]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(mini_y, return_counts=True)[1]/(np.unique(mini_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(train_y, return_counts=True)[1]/(np.unique(train_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(hyper_y, return_counts=True)[1]/(np.unique(hyper_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(val_y, return_counts=True)[1]/(np.unique(val_y, return_counts=True)[1].sum()))\n",
    "print(np.unique(test_y, return_counts=True)[1]/(np.unique(test_y, return_counts=True)[1].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save numpy to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('mini_X', mini_X)\n",
    "#np.save('mini_y', mini_y)\n",
    "#np.save('train_X', train_X)\n",
    "#np.save('train_y', train_y)\n",
    "#np.save('hyper_X', hyper_X)\n",
    "#np.save('hyper_y', hyper_y)\n",
    "#np.save('val_X', val_X)\n",
    "#np.save('val_y', val_y)\n",
    "np.save('test_X', test_X)\n",
    "np.save('test_y', test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the numpy files maybe loaded, converted to tenors, and to dataloader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load numpy files - 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mini_X = np.load('mini_X.npy')\n",
    "#mini_y = np.load('mini_y.npy')\n",
    "train_X = np.load('train_X.npy')\n",
    "train_y = np.load('train_y.npy')\n",
    "#hyper_X = np.load('hyper_X.npy')\n",
    "#hyper_y = np.load('hyper_y.npy')\n",
    "val_X = np.load('val_X.npy')\n",
    "val_y = np.load('val_y.npy')\n",
    "#test_X = np.load('test_X.npy')\n",
    "#test_y = np.load('test_y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to tensors - one at a time otherwise kernel will die b/c of OOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mini\n",
    "mini_seq_CNN = torch.from_numpy(mini_X).float()\n",
    "mini_y_CNN = torch.tensor(mini_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq_CNN = torch.from_numpy(train_X).float()\n",
    "train_y_CNN = torch.tensor(train_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hyperparameter tuning set\n",
    "hyper_seq_CNN = torch.from_numpy(hyper_X).float()\n",
    "hyper_y_CNN = torch.tensor(hyper_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for validation set\n",
    "val_seq_CNN = torch.from_numpy(val_X).float()\n",
    "val_y_CNN = torch.tensor(val_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test set\n",
    "test_seq_CNN = torch.from_numpy(test_X).float()\n",
    "test_y_CNN = torch.tensor(test_y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally save tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(mini_seq_CNN, 'mini_seq_CNN.pt')\n",
    "torch.save(mini_y_CNN, 'mini_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_seq_CNN, 'train_seq_CN.pt')\n",
    "torch.save(train_y_CNN, 'train_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hyper_seq_CNN, 'hyper_seq_CNN.pt')\n",
    "torch.save(hyper_y_CNN, 'hyper_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_seq_CNN, 'val_seq_CNN.pt')\n",
    "torch.save(val_y_CNN,'val_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(test_seq_CNN, 'test_seq_CNN.pt')\n",
    "torch.save(test_y_CNN,'test_y_CNN.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to TensorDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data_CNN = TensorDataset(mini_seq_CNN, mini_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_CNN = TensorDataset(train_seq_CNN, train_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_data_CNN = TensorDataset(hyper_seq_CNN, hyper_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_CNN = TensorDataset(val_seq_CNN, val_y_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_seq_CNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-33cc8823edab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data_CNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq_CNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_CNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_seq_CNN' is not defined"
     ]
    }
   ],
   "source": [
    "test_data_CNN = TensorDataset(test_seq_CNN, test_y_CNN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
